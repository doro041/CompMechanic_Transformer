{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G41BnP5b6aij",
        "outputId": "c75322f6-058a-4fa4-d0d9-397db836e606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'epsilon-transformers'...\n",
            "remote: Enumerating objects: 5666, done.\u001b[K\n",
            "remote: Counting objects: 100% (1049/1049), done.\u001b[K\n",
            "remote: Compressing objects: 100% (506/506), done.\u001b[K\n",
            "remote: Total 5666 (delta 554), reused 889 (delta 527), pack-reused 4617\u001b[K\n",
            "Receiving objects: 100% (5666/5666), 242.68 MiB | 18.85 MiB/s, done.\n",
            "Resolving deltas: 100% (3191/3191), done.\n",
            "/content/epsilon-transformers\n",
            "Obtaining file:///content/epsilon-transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (2.0.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (0.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (3.7.1)\n",
            "Collecting wandb (from epsilon_transformers==0.1)\n",
            "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (1.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (5.15.0)\n",
            "Collecting transformer-lens (from epsilon_transformers==0.1)\n",
            "  Downloading transformer_lens-2.0.0-py3-none-any.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (7.4.4)\n",
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (1.3.1)\n",
            "Collecting black (from epsilon_transformers==0.1)\n",
            "  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy (from epsilon_transformers==0.1)\n",
            "  Downloading mypy-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jaxtyping (from epsilon_transformers==0.1)\n",
            "  Downloading jaxtyping-0.2.29-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire (from epsilon_transformers==0.1)\n",
            "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (2.7.1)\n",
            "Collecting python-dotenv (from epsilon_transformers==0.1)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (4.66.4)\n",
            "Collecting boto3 (from epsilon_transformers==0.1)\n",
            "  Downloading boto3-1.34.117-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->epsilon_transformers==0.1) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->epsilon_transformers==0.1)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black->epsilon_transformers==0.1) (24.0)\n",
            "Collecting pathspec>=0.9.0 (from black->epsilon_transformers==0.1)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->epsilon_transformers==0.1) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->epsilon_transformers==0.1) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->epsilon_transformers==0.1) (4.11.0)\n",
            "Collecting botocore<1.35.0,>=1.34.117 (from boto3->epsilon_transformers==0.1)\n",
            "  Downloading botocore-1.34.117-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->epsilon_transformers==0.1)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->epsilon_transformers==0.1)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->epsilon_transformers==0.1) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->epsilon_transformers==0.1) (2.4.0)\n",
            "Collecting typeguard==2.13.3 (from jaxtyping->epsilon_transformers==0.1)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->epsilon_transformers==0.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->epsilon_transformers==0.1) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->epsilon_transformers==0.1) (8.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->epsilon_transformers==0.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->epsilon_transformers==0.1) (2.18.2)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.10/dist-packages (from PyDrive->epsilon_transformers==0.1) (2.84.0)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyDrive->epsilon_transformers==0.1) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.10/dist-packages (from PyDrive->epsilon_transformers==0.1) (6.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->epsilon_transformers==0.1) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->epsilon_transformers==0.1) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->epsilon_transformers==0.1) (1.2.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->epsilon_transformers==0.1) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->epsilon_transformers==0.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->epsilon_transformers==0.1) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->epsilon_transformers==0.1)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->epsilon_transformers==0.1)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->epsilon_transformers==0.1)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->epsilon_transformers==0.1)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->epsilon_transformers==0.1)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->epsilon_transformers==0.1)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->epsilon_transformers==0.1)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->epsilon_transformers==0.1)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->epsilon_transformers==0.1)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->epsilon_transformers==0.1)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->epsilon_transformers==0.1)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->epsilon_transformers==0.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.23.0 (from transformer-lens->epsilon_transformers==0.1)\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer-lens->epsilon_transformers==0.1)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting better-abc<0.0.4,>=0.0.3 (from transformer-lens->epsilon_transformers==0.1)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Collecting datasets>=2.7.1 (from transformer-lens->epsilon_transformers==0.1)\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens->epsilon_transformers==0.1)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens->epsilon_transformers==0.1)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens->epsilon_transformers==0.1) (13.7.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer-lens->epsilon_transformers==0.1) (0.1.99)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from transformer-lens->epsilon_transformers==0.1) (4.41.1)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->epsilon_transformers==0.1)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->epsilon_transformers==0.1)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->epsilon_transformers==0.1) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->epsilon_transformers==0.1) (5.9.5)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->epsilon_transformers==0.1) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->epsilon_transformers==0.1)\n",
            "  Downloading sentry_sdk-2.3.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb->epsilon_transformers==0.1)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->epsilon_transformers==0.1) (67.7.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens->epsilon_transformers==0.1) (0.23.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens->epsilon_transformers==0.1) (0.4.3)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.117->boto3->epsilon_transformers==0.1) (2.0.7)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<3,>=2.0.0 (from wandb->epsilon_transformers==0.1)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (3.9.5)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->epsilon_transformers==0.1)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (4.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive->epsilon_transformers==0.1) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive->epsilon_transformers==0.1) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive->epsilon_transformers==0.1) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->epsilon_transformers==0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->epsilon_transformers==0.1) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->epsilon_transformers==0.1) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens->epsilon_transformers==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens->epsilon_transformers==0.1) (2.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer-lens->epsilon_transformers==0.1) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer-lens->epsilon_transformers==0.1) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->epsilon_transformers==0.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->epsilon_transformers==0.1) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (4.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->epsilon_transformers==0.1)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (1.63.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (5.3.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens->epsilon_transformers==0.1) (0.1.2)\n",
            "Building wheels for collected packages: epsilon_transformers, fire\n",
            "  Building editable for epsilon_transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for epsilon_transformers: filename=epsilon_transformers-0.1-0.editable-py3-none-any.whl size=2941 sha256=b3587208d08550c2ec44450876842f703c7416c3115b8e31d738716e95e0411b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q4vbmt3g/wheels/b3/d7/07/1df0a2f3e559b1b2381019428554e9038d28af7b8e5af5a83f\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117029 sha256=e8cdf74506f5ff7cd46cad507446bc89d2f76f2f23a2aac66a69e423bf65d29a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n",
            "Successfully built epsilon_transformers fire\n",
            "Installing collected packages: better-abc, xxhash, typeguard, smmap, setproctitle, sentry-sdk, requests, python-dotenv, pathspec, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, jmespath, fire, fancy-einsum, einops, docker-pycreds, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, mypy, multiprocess, jaxtyping, gitdb, botocore, black, s3transfer, nvidia-cusolver-cu12, gitpython, wandb, datasets, boto3, accelerate, transformer-lens, epsilon_transformers\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.30.1 beartype-0.14.1 better-abc-0.0.3 black-24.4.2 boto3-1.34.117 botocore-1.34.117 datasets-2.19.2 dill-0.3.8 docker-pycreds-0.4.0 einops-0.8.0 epsilon_transformers-0.1 fancy-einsum-0.0.3 fire-0.6.0 gitdb-4.0.11 gitpython-3.1.43 jaxtyping-0.2.29 jmespath-1.0.1 multiprocess-0.70.16 mypy-1.10.0 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pathspec-0.12.1 python-dotenv-1.0.1 requests-2.32.3 s3transfer-0.10.1 sentry-sdk-2.3.1 setproctitle-1.3.3 smmap-5.0.1 transformer-lens-2.0.0 typeguard-2.13.3 wandb-0.17.0 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Clone the specific branch hackathon-prep\n",
        "!git clone --branch hackathon-prep https://github.com/adamimos/epsilon-transformers.git\n",
        "%cd epsilon-transformers\n",
        "\n",
        "# Step 2: Install the necessary dependencies\n",
        "!pip install -e .\n",
        "\n",
        "# Step 3: Install gdown if not already installed\n",
        "#!pip install gdown\n",
        "\n",
        "# Step 4: Download the RRXOR experiment data\n",
        "#!gdown \"https://drive.google.com/uc?id=1PYMcdvvJ_FW31rQDBmnNKz9LOyFEcfqQ\" -O vfs4q106-rrxor.zip\n",
        "\n",
        "# Step 5: Unzip the data in the correct location\n",
        "#!unzip vfs4q106-rrxor.zip -d examples/models/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.process.processes import ZeroOneR, GoldenMean, Mess3\n",
        "\n",
        "proc1 = ZeroOneR()\n",
        "proc2 = GoldenMean(1,1)\n",
        "\n",
        "print(proc1.transition_matrix)\n",
        "print(proc2.transition_matrix)\n",
        "print(proc1.vocab_len)\n",
        "print(type(proc1.transition_matrix))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5De9TYs6fV0",
        "outputId": "fd803f93-fa64-48fe-f311-4f7225e277ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.  1.  0. ]\n",
            "  [0.  0.  0. ]\n",
            "  [0.5 0.  0. ]]\n",
            "\n",
            " [[0.  0.  0. ]\n",
            "  [0.  0.  1. ]\n",
            "  [0.5 0.  0. ]]]\n",
            "[[[0.5 0. ]\n",
            "  [1.  0. ]]\n",
            "\n",
            " [[0.  0.5]\n",
            "  [0.  0. ]]]\n",
            "2\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.process.Process import Process\n",
        "import numpy as np\n",
        "\n",
        "class GluedProcess(Process):\n",
        "  def __init__(self, proc1, proc2, join_on=dict(), weights=(0.5,0.5)):\n",
        "        # join_on is a dictionary that maps vocubulary from Process 2 to Process 1\n",
        "        # So join_on = {0: 1} means that emitting a \"0\" in Process 2 looks the same\n",
        "        # as emitting a \"1\" in Process 1, but all other vocubulary of Process 1\n",
        "        # is discernable.\n",
        "\n",
        "        self.name = proc1.name + \"+\" + proc2.name\n",
        "        self.proc1 = proc1\n",
        "        self.proc2 = proc2\n",
        "        self.weights = weights\n",
        "        self.join_on = join_on\n",
        "        super().__init__()\n",
        "\n",
        "  def _create_hmm(self):\n",
        "        n_states = len(self.proc1.state_names_dict)\n",
        "        state_names = self.proc1.state_names_dict.copy()\n",
        "        for key, val in self.proc2.state_names_dict.items():\n",
        "          # choose a unique name for merged state in case it is already occupied\n",
        "          while key in state_names:\n",
        "            key += \"_\"\n",
        "          state_names[key] = n_states\n",
        "          n_states += 1\n",
        "\n",
        "        # For a combination in which the vocabulary is disjoint, the vocab\n",
        "        # size is the sum, else the larger of the two\n",
        "        vocab_len = self.proc1.vocab_len + self.proc2.vocab_len - len(self.join_on)\n",
        "        T = np.zeros((vocab_len, n_states, n_states))\n",
        "\n",
        "        # Copying over values from Proc1\n",
        "        shape1 = self.proc1.transition_matrix.shape\n",
        "        print(shape1)\n",
        "        T[:shape1[0],:shape1[1],:shape1[2]] = self.proc1.transition_matrix\n",
        "\n",
        "        # Copying from Proc2\n",
        "        new_v = 0 # This counts the number of new vocabulary tokens\n",
        "        for v in range(self.proc2.vocab_len):\n",
        "          if v in self.join_on:\n",
        "            T[self.join_on[v],shape1[1]:, shape1[2]:] = self.proc2.transition_matrix[v,:,:]\n",
        "          else:\n",
        "            T[shape1[0]+new_v,shape1[1]:, shape1[2]:] = self.proc2.transition_matrix[v,:,:]\n",
        "            new_v += 1\n",
        "\n",
        "        print(T)\n",
        "        return T, state_names\n",
        "\n",
        "  @property\n",
        "  def steady_state_vector(self):\n",
        "      steady_state_vector = np.concatenate((self.proc1.steady_state_vector * self.weights[0], self.proc2.steady_state_vector * self.weights[1]))\n",
        "      #steady_state_vector = np.ones((self.num_states))\n",
        "\n",
        "      out = steady_state_vector / steady_state_vector.sum()\n",
        "      assert out.ndim == 1\n",
        "      assert len(out) == self.num_states\n",
        "      return out\n",
        "\n",
        "\n",
        "class BiasedCoin(Process):\n",
        "    def __init__(self, bias: float = 0.5):\n",
        "        self.name = \"bc\"\n",
        "        self.p = bias\n",
        "        super().__init__()\n",
        "\n",
        "    def _create_hmm(self):\n",
        "        T = np.zeros((2, 1, 1))\n",
        "        state_names = {\"0\": 0}\n",
        "        T[0, state_names[\"0\"], state_names[\"0\"]] = self.p\n",
        "        T[1, state_names[\"0\"], state_names[\"0\"]] = 1-self.p\n",
        "\n",
        "        return T, state_names\n"
      ],
      "metadata": {
        "id": "CIaVSyo3puiV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.visualization.plots import _project_to_simplex\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "proc1 = BiasedCoin(0.5)\n",
        "proc2 = BiasedCoin(0.3)\n",
        "proc3 = BiasedCoin(0.7)\n",
        "process = GluedProcess(proc3, GluedProcess(proc1, proc2, {0:0}), {0:0,1:1}, weights=(1, 2))\n",
        "mixed_state_tree = process.derive_mixed_state_presentation(depth=14)\n",
        "MSP_transition_matrix = mixed_state_tree.build_msp_transition_matrix()\n",
        "\n",
        "tree_paths, tree_beliefs = mixed_state_tree.paths_and_belief_states\n",
        "\n",
        "msp_beliefs = [tuple(round(b, 5) for b in belief) for belief in tree_beliefs]\n",
        "msp_belief_index = {b: i for i, b in enumerate(set(msp_beliefs))}\n",
        "ground_truth_simplex = _project_to_simplex(np.array(list(msp_belief_index.keys())))\n",
        "plt.figure(figsize=(4.5, 4))\n",
        "plt.scatter(ground_truth_simplex[0], ground_truth_simplex[1], c=[k for k in list(msp_belief_index.keys())], alpha=.75, s=5)\n",
        "plt.title(\"Ground Truth Simplex\")\n",
        "plt.gca().set_axis_off()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "RoJ-QZgithtp",
        "outputId": "527ce2eb-921c-4928-80ec-0899db53de58"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 1, 1)\n",
            "[[[0.5 0. ]\n",
            "  [0.  0.3]]\n",
            "\n",
            " [[0.5 0. ]\n",
            "  [0.  0. ]]\n",
            "\n",
            " [[0.  0. ]\n",
            "  [0.  0.7]]]\n",
            "(2, 1, 1)\n",
            "[[[0.7 0.  0. ]\n",
            "  [0.  0.5 0. ]\n",
            "  [0.  0.  0.3]]\n",
            "\n",
            " [[0.3 0.  0. ]\n",
            "  [0.  0.5 0. ]\n",
            "  [0.  0.  0. ]]\n",
            "\n",
            " [[0.  0.  0. ]\n",
            "  [0.  0.  0. ]\n",
            "  [0.  0.  0.7]]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 450x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer training\n"
      ],
      "metadata": {
        "id": "0j8974VJ6bwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "eBoj5FRhEB4O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.persistence import S3Persister, HackyPersister\n",
        "from epsilon_transformers.training.configs.model_configs import RawModelConfig\n",
        "from epsilon_transformers.process.processes import RRXOR, Mess3\n",
        "from epsilon_transformers.analysis.activation_analysis import get_beliefs_for_transformer_inputs\n",
        "from epsilon_transformers.visualization.plots import _project_to_simplex\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "Qj86qldcENSL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transformer_data_from_process(process, n_ctx):\n",
        "    mixed_state_tree = process.derive_mixed_state_presentation(depth=n_ctx+1)\n",
        "    tree_paths, tree_beliefs = mixed_state_tree.paths_and_belief_states\n",
        "    transformer_data = [x for x in tree_paths if len(x) == n_ctx+1]\n",
        "    transformer_data = torch.tensor(transformer_data)\n",
        "    transformer_input = transformer_data[:, :-1]\n",
        "    transformer_target = transformer_data[:, 1:]\n",
        "    return transformer_input, transformer_target\n",
        "\n",
        "def get_lower_bound_for_cross_entropy(process, n_ctx):\n",
        "    mixed_state_tree = process.derive_mixed_state_presentation(depth=n_ctx+1)\n",
        "    myopic_entropy = mixed_state_tree.myopic_entropy\n",
        "    return myopic_entropy[1:]"
      ],
      "metadata": {
        "id": "z83TDfiCEVX7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = HookedTransformerConfig(\n",
        "    n_layers = 1,\n",
        "    n_heads = 3,\n",
        "    d_model = 9,\n",
        "    d_head = 3,\n",
        "    d_mlp = 9,\n",
        "    act_fn = \"relu\",\n",
        "    normalization_type=None,\n",
        "    d_vocab=3,\n",
        "    n_ctx=8,\n",
        "    init_weights=True,\n",
        "    device=device,\n",
        "    seed = 999,\n",
        ")"
      ],
      "metadata": {
        "id": "Skv_LKl8Ekw0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from typing import List, Tuple, Iterable\n",
        "\n",
        "\n",
        "class ProcessDataset(IterableDataset):\n",
        "\n",
        "    def __init__(self, process, sequence_length, num_samples, fixed=False):\n",
        "        super().__init__()\n",
        "        self.process = process\n",
        "        self.sequence_length = sequence_length\n",
        "        self.num_samples = num_samples\n",
        "        self.fixed = fixed\n",
        "        if self.fixed:\n",
        "          self.samples = list(self._get_samples())\n",
        "        else:\n",
        "          self.samples = None\n",
        "\n",
        "    def _get_samples(self):\n",
        "      return process.yield_emissions(\n",
        "            sequence_len=self.num_samples * (self.sequence_length + 1)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __iter__(self) -> Iterable[Tuple[List[int]]]:\n",
        "        samples = self._get_samples() if self.samples is None else iter(self.samples)\n",
        "        for _ in range(self.num_samples):\n",
        "            process_history = [\n",
        "                next(samples) for _ in range(self.sequence_length + 1)\n",
        "            ]\n",
        "            yield (process_history[:-1], process_history[1:])\n",
        "\n",
        "\n",
        "def process_dataset_collate_fn(batch: List[Tuple[List[int]]]):\n",
        "    data = [x[0] for x in batch]\n",
        "    labels = [x[1] for x in batch]\n",
        "    return torch.tensor(data, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "\n",
        "train_dataset = ProcessDataset(process, sequence_length=cfg.n_ctx, num_samples=10000,\n",
        "                                     fixed=False)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=100, collate_fn=process_dataset_collate_fn)\n",
        "val_dataset = ProcessDataset(process, sequence_length=cfg.n_ctx, num_samples=1000,\n",
        "                                   fixed=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=100, collate_fn=process_dataset_collate_fn)"
      ],
      "metadata": {
        "id": "xuMTautumzgr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc1 = BiasedCoin(0.5)\n",
        "proc2 = BiasedCoin(0.3)\n",
        "proc3 = BiasedCoin(0.7)\n",
        "process = GluedProcess(proc3, GluedProcess(proc1, proc2, {0:0}), {0:0,1:1}, weights=(1, 2))\n",
        "transformer_inputs, transformer_targets = get_transformer_data_from_process(process, cfg.n_ctx)\n",
        "minimum_loss = np.mean(get_lower_bound_for_cross_entropy(process, cfg.n_ctx))\n",
        "print(f\"Minimum Loss: {minimum_loss}\")\n",
        "transformer_inputs = transformer_inputs.to(device)\n",
        "transformer_targets = transformer_targets.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYnAUPesEstY",
        "outputId": "514b8460-27d3-495a-9fcf-3ba64da2b84c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 1, 1)\n",
            "[[[0.5 0. ]\n",
            "  [0.  0.3]]\n",
            "\n",
            " [[0.5 0. ]\n",
            "  [0.  0. ]]\n",
            "\n",
            " [[0.  0. ]\n",
            "  [0.  0.7]]]\n",
            "(2, 1, 1)\n",
            "[[[0.7 0.  0. ]\n",
            "  [0.  0.5 0. ]\n",
            "  [0.  0.  0.3]]\n",
            "\n",
            " [[0.3 0.  0. ]\n",
            "  [0.  0.5 0. ]\n",
            "  [0.  0.  0. ]]\n",
            "\n",
            " [[0.  0.  0. ]\n",
            "  [0.  0.  0. ]\n",
            "  [0.  0.  0.7]]]\n",
            "Minimum Loss: 0.6859985357149234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = HookedTransformer(cfg)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)"
      ],
      "metadata": {
        "id": "7xKW7GVvFMaV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "for epoch in tqdm(range(10000)):\n",
        "    train_logits = model(transformer_inputs)\n",
        "    train_loss = loss_fn(train_logits.view(-1, cfg.d_vocab), transformer_targets.flatten())\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{10000}, Loss: {train_loss.item()/minimum_loss*100} percent of minimum, LR: {optimizer.param_groups[0]['lr']}\")\n",
        "        scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iylTEAD_FQvp",
        "outputId": "49f8b870-4942-4aa7-9545-5a9a57714774"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 5/10000 [00:00<09:26, 17.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000, Loss: 167.16372051398648 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 103/10000 [00:03<07:14, 22.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101/10000, Loss: 121.71053764922473 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 203/10000 [00:12<11:47, 13.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 201/10000, Loss: 112.03301650384164 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 302/10000 [00:18<08:15, 19.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 301/10000, Loss: 109.27813781204902 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 403/10000 [00:25<12:55, 12.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 401/10000, Loss: 108.24576752121496 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 503/10000 [00:30<06:33, 24.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 501/10000, Loss: 107.87692172291845 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 602/10000 [00:34<06:50, 22.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 601/10000, Loss: 107.72360886548418 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 703/10000 [00:42<07:24, 20.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 701/10000, Loss: 107.64554920488972 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 807/10000 [00:46<03:53, 39.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 801/10000, Loss: 107.59820424823575 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 908/10000 [00:48<03:47, 39.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 901/10000, Loss: 107.56556064351028 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1006/10000 [00:51<05:30, 27.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1001/10000, Loss: 107.5625543386833 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 1106/10000 [00:54<03:50, 38.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1101/10000, Loss: 107.5598608285782 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 1206/10000 [00:57<03:39, 40.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1201/10000, Loss: 107.55723682841128 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 1308/10000 [00:59<03:38, 39.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1301/10000, Loss: 107.5547084044094 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 1405/10000 [01:02<03:32, 40.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1401/10000, Loss: 107.55220604663431 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 1504/10000 [01:05<05:15, 26.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1501/10000, Loss: 107.54978188753972 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 1607/10000 [01:08<03:32, 39.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1601/10000, Loss: 107.54742723838334 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 1706/10000 [01:11<03:29, 39.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1701/10000, Loss: 107.54514209916512 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 1804/10000 [01:13<03:22, 40.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1801/10000, Loss: 107.54291778114285 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 1905/10000 [01:16<03:31, 38.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1901/10000, Loss: 107.54072821808967 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2006/10000 [01:19<05:23, 24.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2001/10000, Loss: 107.54050231079052 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 2103/10000 [01:24<06:25, 20.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2101/10000, Loss: 107.54029378097594 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 2203/10000 [01:29<07:16, 17.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2201/10000, Loss: 107.54006787367678 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 2304/10000 [01:34<05:08, 24.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2301/10000, Loss: 107.5398593438622 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 2407/10000 [01:37<03:08, 40.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2401/10000, Loss: 107.53965081404762 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 2506/10000 [01:39<03:09, 39.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2501/10000, Loss: 107.53944228423302 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 2608/10000 [01:42<03:00, 40.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2601/10000, Loss: 107.53923375441843 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 2708/10000 [01:44<03:03, 39.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2701/10000, Loss: 107.5390078471193 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 2805/10000 [01:48<04:46, 25.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2801/10000, Loss: 107.5387993173047 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 2906/10000 [01:50<02:57, 39.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2901/10000, Loss: 107.53859078749014 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3006/10000 [01:53<02:52, 40.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3001/10000, Loss: 107.53857341000557 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 3106/10000 [01:55<02:52, 40.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3101/10000, Loss: 107.53855603252103 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 3199/10000 [01:58<04:04, 27.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3201/10000, Loss: 107.53852127755192 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 3307/10000 [02:04<02:49, 39.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3301/10000, Loss: 107.53850390006738 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 3409/10000 [02:07<02:47, 39.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3401/10000, Loss: 107.53848652258282 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 3509/10000 [02:09<02:44, 39.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3501/10000, Loss: 107.53846914509828 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 3608/10000 [02:12<02:40, 39.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3601/10000, Loss: 107.53844307887147 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 3703/10000 [02:15<04:11, 25.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3701/10000, Loss: 107.53841701264464 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 3805/10000 [02:18<02:33, 40.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3801/10000, Loss: 107.53839094641779 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 3905/10000 [02:20<02:34, 39.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3901/10000, Loss: 107.53837356893325 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4006/10000 [02:23<02:25, 41.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4001/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 4106/10000 [02:25<02:22, 41.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4101/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 4204/10000 [02:29<03:49, 25.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4201/10000, Loss: 107.53838225767554 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 4305/10000 [02:31<02:23, 39.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4301/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 4408/10000 [02:34<02:17, 40.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4401/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 4508/10000 [02:37<02:18, 39.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4501/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 4606/10000 [02:39<02:15, 39.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4601/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 4704/10000 [02:43<03:30, 25.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4701/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 4806/10000 [02:45<02:08, 40.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4801/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 4909/10000 [02:48<02:06, 40.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4901/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5006/10000 [02:50<02:03, 40.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5001/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 5109/10000 [02:53<02:00, 40.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5101/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 5206/10000 [02:57<03:09, 25.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5201/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 5304/10000 [02:59<01:56, 40.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5301/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 5408/10000 [03:03<02:47, 27.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5401/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 5507/10000 [03:05<01:53, 39.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5501/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 5604/10000 [03:08<02:40, 27.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5601/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 5706/10000 [03:11<01:52, 38.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5701/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 5808/10000 [03:14<01:45, 39.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5801/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 5906/10000 [03:16<01:42, 40.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5901/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6008/10000 [03:19<01:38, 40.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6001/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 6104/10000 [03:22<02:31, 25.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6101/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 6209/10000 [03:25<01:35, 39.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6201/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 6307/10000 [03:28<01:30, 40.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6301/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 6405/10000 [03:30<01:29, 40.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6401/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 6504/10000 [03:33<01:26, 40.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6501/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 6604/10000 [03:36<02:11, 25.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6601/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 6708/10000 [03:39<01:23, 39.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6701/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 6809/10000 [03:42<01:19, 40.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6801/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 6908/10000 [03:44<01:16, 40.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6901/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7004/10000 [03:46<01:15, 39.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7001/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 7104/10000 [03:50<01:56, 24.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7101/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 7209/10000 [03:53<01:10, 39.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7201/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 7306/10000 [03:55<01:07, 40.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7301/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 7408/10000 [03:58<01:06, 39.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7401/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 7506/10000 [04:00<01:02, 39.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7501/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 7605/10000 [04:04<01:34, 25.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7601/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 7707/10000 [04:07<00:58, 39.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7701/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 7805/10000 [04:09<00:54, 40.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7801/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 7909/10000 [04:12<00:51, 40.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7901/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8008/10000 [04:14<00:50, 39.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8001/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 8103/10000 [04:18<01:16, 24.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8101/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 8209/10000 [04:21<00:43, 40.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8201/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 8306/10000 [04:23<00:42, 40.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8301/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 8405/10000 [04:25<00:39, 40.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8401/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 8506/10000 [04:28<00:36, 40.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8501/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 8605/10000 [04:32<00:56, 24.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8601/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 8702/10000 [04:38<01:33, 13.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8701/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 8802/10000 [04:45<01:39, 12.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8801/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 8903/10000 [04:51<00:36, 30.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8901/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9007/10000 [04:54<00:24, 40.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9001/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 9106/10000 [04:57<00:25, 34.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9101/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 9206/10000 [05:00<00:23, 33.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9201/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 9306/10000 [05:03<00:18, 38.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9301/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 9407/10000 [05:06<00:15, 38.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9401/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 9505/10000 [05:08<00:16, 30.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9501/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 9605/10000 [05:12<00:16, 24.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9601/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 9708/10000 [05:16<00:07, 38.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9701/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 9805/10000 [05:19<00:05, 38.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9801/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 9906/10000 [05:21<00:02, 40.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9901/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [05:23<00:00, 30.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "# Save the entire model into current directory\n",
        "torch.save(model, 'my_model.pth')\n",
        "\n"
      ],
      "metadata": {
        "id": "1TrDvgmKCXq4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr2SMe39Uo4D",
        "outputId": "22878e2a-1628-4324-cdb3-6d2a6f8dcac8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 48\n",
            "drwxr-xr-x 8 root root  4096 Jun  3 15:54 epsilon_transformers\n",
            "drwxr-xr-x 2 root root  4096 Jun  3 15:53 epsilon_transformers.egg-info\n",
            "drwxr-xr-x 2 root root  4096 Jun  3 15:53 examples\n",
            "-rw-r--r-- 1 root root 19574 Jun  3 16:00 my_model.pth\n",
            "-rw-r--r-- 1 root root   584 Jun  3 15:53 pyproject.toml\n",
            "-rw-r--r-- 1 root root  2686 Jun  3 15:53 README.md\n",
            "drwxr-xr-x 2 root root  4096 Jun  3 15:53 scripts\n",
            "drwxr-xr-x 2 root root  4096 Jun  3 15:53 tests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "loaded_model = torch.load('my_model.pth')\n",
        "\n",
        "# Check if the model is the same model.\n",
        "# By comparing the ouputs and parameters to process\n",
        "input_example = torch.randint(low=0, high=proc1.vocab_len, size=(1, 8))\n",
        "input_example = input_example.long()\n",
        "original_output = model(input_example)\n",
        "loaded_output = loaded_model(input_example)\n",
        "print(torch.equal(original_output, loaded_output))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQYwhbJDVBbB",
        "outputId": "3169736c-a81d-4726-b6ff-4eb9c749f901"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "transformer_inputs = [x for x in tree_paths if len(x) == cfg.n_ctx]\n",
        "transformer_inputs = torch.tensor(transformer_inputs, dtype=torch.int).to(device)\n",
        "\n",
        "# print first few batches\n",
        "print(transformer_inputs[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufjqUp0sWKNk",
        "outputId": "144e914c-f97c-45fc-cc42-9a3f3a495797"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 0, 1, 1, 1, 1, 0],\n",
            "        [0, 1, 0, 1, 1, 1, 1, 1],\n",
            "        [1, 0, 0, 1, 0, 1, 0, 0],\n",
            "        [1, 0, 0, 1, 0, 1, 0, 1],\n",
            "        [0, 2, 2, 2, 2, 2, 0, 0]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_input_beliefs, transformer_input_belief_indices = get_beliefs_for_transformer_inputs(transformer_inputs, msp_belief_index, tree_paths, tree_beliefs)\n",
        "print(f\"Transformer Input Beliefs: {transformer_input_beliefs.shape}, Transformer Input Belief Indices: {transformer_input_belief_indices.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgVaarV5W5jV",
        "outputId": "614846cf-6041-41d9-9338-5f8bac190240"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer Input Beliefs: torch.Size([511, 8, 3]), Transformer Input Belief Indices: torch.Size([511, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = torch.load('my_model.pth')\n",
        "_, activations = model.run_with_cache(transformer_inputs, names_filter=lambda x: 'resid_post' in x)\n",
        "print(activations.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW9WHw3CY2Wl",
        "outputId": "01107b6c-4549-4ea8-d56d-c91b37fe3649"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['blocks.0.hook_resid_post'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we now have activations [batch, n_ctx, d_model]\n",
        "# and we have transformer_input_beliefs [batch, n_ctx, belief_dim]\n",
        "# and we have transformer_input_belief_indices [batch, n_ctx]\n",
        "\n",
        "# in the end we want to do linear regression between the activations and the transformer_input_beliefs\n",
        "def run_activation_to_beliefs_regression(activations, ground_truth_beliefs):\n",
        "\n",
        "    # make sure the first two dimensions are the same\n",
        "    assert activations.shape[0] == ground_truth_beliefs.shape[0]\n",
        "    assert activations.shape[1] == ground_truth_beliefs.shape[1]\n",
        "\n",
        "    # flatten the activations\n",
        "    batch_size, n_ctx, d_model = activations.shape\n",
        "    belief_dim = ground_truth_beliefs.shape[-1]\n",
        "    activations_flattened = activations.view(-1, d_model) # [batch * n_ctx, d_model]\n",
        "    ground_truth_beliefs_flattened = ground_truth_beliefs.view(-1, belief_dim) # [batch * n_ctx, belief_dim]\n",
        "\n",
        "    # run the regression\n",
        "    regression = LinearRegression()\n",
        "    regression.fit(activations_flattened, ground_truth_beliefs_flattened)\n",
        "\n",
        "    # get the belief predictions\n",
        "    belief_predictions = regression.predict(activations_flattened) # [batch * n_ctx, belief_dim]\n",
        "    belief_predictions = belief_predictions.reshape(batch_size, n_ctx, belief_dim)\n",
        "\n",
        "    return regression, belief_predictions\n"
      ],
      "metadata": {
        "id": "-dZE9wz0bPL2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acts = torch.cat([v for k, v in activations.items()], dim=-1)\n",
        "regression, belief_predictions = run_activation_to_beliefs_regression(acts, transformer_input_beliefs)\n",
        "print(f\"Shape of belief_predictions: {belief_predictions.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6Hj5Rc_bSbg",
        "outputId": "6622ece5-ebb8-4a36-e5bb-e6f2e76826d2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of belief_predictions: (511, 8, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.visualization import plots\n",
        "print(dir(plots))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcIPPJhvjVIK",
        "outputId": "f8a87514-0d98-4f32-ba2a-9ffb3e760908"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Figure', 'Float', 'Image', 'Literal', 'RawModelConfig', 'ZeroOneR', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_project_to_simplex', 'find_msp_subspace_in_residual_stream', 'fire', 'np', 'pd', 'plt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.analysis.activation_analysis import find_msp_subspace_in_residual_stream\n",
        "from epsilon_transformers.process.processes import Mess3\n",
        "\n",
        "\n",
        "belief_predictions_flattened = belief_predictions.reshape(-1, 3)\n",
        "transformer_input_belief_flattened = transformer_input_beliefs.reshape(-1, 3)\n",
        "\n",
        "# project to simplex\n",
        "belief_true_projected = _project_to_simplex(transformer_input_belief_flattened)\n",
        "belief_pred_projected = _project_to_simplex(belief_predictions_flattened)\n",
        "\n",
        "rgb_colors =  transformer_input_belief_flattened.cpu().numpy()\n",
        "#rgb_colors = rgb_colors.astype(int)\n",
        "\n",
        "sns.set_context(\"paper\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
        "\n",
        "# Plotting the true beliefs projected onto the simplex\n",
        "axes[0].scatter(belief_true_projected[0], belief_true_projected[1], marker='.', c=rgb_colors, alpha=0.2, s=0.5)\n",
        "axes[0].axis('off')\n",
        "axes[0].set_title(\"Ground Truth Simplex\")\n",
        "\n",
        "# Plotting the predicted beliefs projected onto the simplex\n",
        "axes[1].scatter(belief_pred_projected[0], belief_pred_projected[1], marker='.', c=rgb_colors, alpha=0.3, s=0.01)\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title(\"Residual Stream Simplex\")\n",
        "\n",
        "# Adjust layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "QsNXkP8XdLs7",
        "outputId": "28dae9ec-9620-40d5-856c-99d2c0db0c1b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}