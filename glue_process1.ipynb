{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "bS9ta2JGhMVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G41BnP5b6aij",
        "outputId": "cdc3e6bf-5012-4375-ca2c-3a3cbf3d2b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'epsilon-transformers' already exists and is not an empty directory.\n",
            "/content/epsilon-transformers\n",
            "Obtaining file:///content/epsilon-transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (2.0.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (0.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (3.7.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (0.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (1.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (5.15.0)\n",
            "Requirement already satisfied: transformer-lens in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (2.0.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (7.4.4)\n",
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (1.3.1)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (24.4.2)\n",
            "Requirement already satisfied: mypy in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (1.10.0)\n",
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (0.2.29)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (2.7.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (4.66.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from epsilon_transformers==0.1) (1.34.117)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->epsilon_transformers==0.1) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black->epsilon_transformers==0.1) (1.0.0)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black->epsilon_transformers==0.1) (24.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black->epsilon_transformers==0.1) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->epsilon_transformers==0.1) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->epsilon_transformers==0.1) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->epsilon_transformers==0.1) (4.11.0)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.117 in /usr/local/lib/python3.10/dist-packages (from boto3->epsilon_transformers==0.1) (1.34.117)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->epsilon_transformers==0.1) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->epsilon_transformers==0.1) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->epsilon_transformers==0.1) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->epsilon_transformers==0.1) (2.4.0)\n",
            "Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping->epsilon_transformers==0.1) (2.13.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->epsilon_transformers==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->epsilon_transformers==0.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->epsilon_transformers==0.1) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->epsilon_transformers==0.1) (8.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->epsilon_transformers==0.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->epsilon_transformers==0.1) (2.18.2)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.10/dist-packages (from PyDrive->epsilon_transformers==0.1) (2.84.0)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyDrive->epsilon_transformers==0.1) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.10/dist-packages (from PyDrive->epsilon_transformers==0.1) (6.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->epsilon_transformers==0.1) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->epsilon_transformers==0.1) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->epsilon_transformers==0.1) (1.2.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->epsilon_transformers==0.1) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->epsilon_transformers==0.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->epsilon_transformers==0.1) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->epsilon_transformers==0.1) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->epsilon_transformers==0.1) (12.5.40)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens->epsilon_transformers==0.1) (0.30.1)\n",
            "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens->epsilon_transformers==0.1) (0.14.1)\n",
            "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer-lens->epsilon_transformers==0.1) (0.0.3)\n",
            "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens->epsilon_transformers==0.1) (2.19.1)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens->epsilon_transformers==0.1) (0.8.0)\n",
            "Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer-lens->epsilon_transformers==0.1) (0.0.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens->epsilon_transformers==0.1) (13.7.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer-lens->epsilon_transformers==0.1) (0.1.99)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from transformer-lens->epsilon_transformers==0.1) (4.41.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->epsilon_transformers==0.1) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->epsilon_transformers==0.1) (3.1.43)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->epsilon_transformers==0.1) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->epsilon_transformers==0.1) (5.9.5)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->epsilon_transformers==0.1) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->epsilon_transformers==0.1) (2.3.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->epsilon_transformers==0.1) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->epsilon_transformers==0.1) (67.7.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens->epsilon_transformers==0.1) (0.23.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens->epsilon_transformers==0.1) (0.4.3)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.117->boto3->epsilon_transformers==0.1) (2.0.7)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (3.9.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->epsilon_transformers==0.1) (4.0.11)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (4.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive->epsilon_transformers==0.1) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive->epsilon_transformers==0.1) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive->epsilon_transformers==0.1) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->epsilon_transformers==0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->epsilon_transformers==0.1) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->epsilon_transformers==0.1) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens->epsilon_transformers==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens->epsilon_transformers==0.1) (2.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer-lens->epsilon_transformers==0.1) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer-lens->epsilon_transformers==0.1) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->epsilon_transformers==0.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->epsilon_transformers==0.1) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens->epsilon_transformers==0.1) (4.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->epsilon_transformers==0.1) (5.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (1.63.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.2->PyDrive->epsilon_transformers==0.1) (5.3.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens->epsilon_transformers==0.1) (0.1.2)\n",
            "Building wheels for collected packages: epsilon_transformers\n",
            "  Building editable for epsilon_transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for epsilon_transformers: filename=epsilon_transformers-0.1-0.editable-py3-none-any.whl size=2941 sha256=c49184dbf73f838e7dab21a99e9c358faeaf1c5ce187b767890afd25adf38b8c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-al6omjla/wheels/b3/d7/07/1df0a2f3e559b1b2381019428554e9038d28af7b8e5af5a83f\n",
            "Successfully built epsilon_transformers\n",
            "Installing collected packages: epsilon_transformers\n",
            "  Attempting uninstall: epsilon_transformers\n",
            "    Found existing installation: epsilon_transformers 0.1\n",
            "    Uninstalling epsilon_transformers-0.1:\n",
            "      Successfully uninstalled epsilon_transformers-0.1\n",
            "Successfully installed epsilon_transformers-0.1\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Clone the specific branch hackathon-prep\n",
        "!git clone --branch hackathon-prep https://github.com/adamimos/epsilon-transformers.git\n",
        "%cd epsilon-transformers\n",
        "\n",
        "# Step 2: Install the necessary dependencies\n",
        "!pip install -e .\n",
        "\n",
        "# Step 3: Install gdown if not already installed\n",
        "#!pip install gdown\n",
        "\n",
        "# Step 4: Download the RRXOR experiment data\n",
        "#!gdown \"https://drive.google.com/uc?id=1PYMcdvvJ_FW31rQDBmnNKz9LOyFEcfqQ\" -O vfs4q106-rrxor.zip\n",
        "\n",
        "# Step 5: Unzip the data in the correct location\n",
        "#!unzip vfs4q106-rrxor.zip -d examples/models/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.process.processes import ZeroOneR, GoldenMean, Mess3\n",
        "\n",
        "proc1 = ZeroOneR()\n",
        "proc2 = GoldenMean(1,1)\n",
        "\n",
        "print(proc1.transition_matrix)\n",
        "print(proc2.transition_matrix)\n",
        "print(proc1.vocab_len)\n",
        "print(type(proc1.transition_matrix))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5De9TYs6fV0",
        "outputId": "6eb63953-62fa-4bfb-df0d-d797ea8afe58"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.  1.  0. ]\n",
            "  [0.  0.  0. ]\n",
            "  [0.5 0.  0. ]]\n",
            "\n",
            " [[0.  0.  0. ]\n",
            "  [0.  0.  1. ]\n",
            "  [0.5 0.  0. ]]]\n",
            "[[[0.5 0. ]\n",
            "  [1.  0. ]]\n",
            "\n",
            " [[0.  0.5]\n",
            "  [0.  0. ]]]\n",
            "2\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.process.Process import Process\n",
        "import numpy as np\n",
        "\n",
        "class GluedProcess(Process):\n",
        "  def __init__(self, proc1, proc2, join_on=dict(), weights=(0.5,0.5)):\n",
        "        # join_on is a dictionary that maps vocubulary from Process 2 to Process 1\n",
        "        # So join_on = {0: 1} means that emitting a \"0\" in Process 2 looks the same\n",
        "        # as emitting a \"1\" in Process 1, but all other vocubulary of Process 1\n",
        "        # is discernable.\n",
        "\n",
        "        self.name = proc1.name + \"+\" + proc2.name\n",
        "        self.proc1 = proc1\n",
        "        self.proc2 = proc2\n",
        "        self.weights = weights\n",
        "        self.join_on = join_on\n",
        "        super().__init__()\n",
        "\n",
        "  def _create_hmm(self):\n",
        "        n_states = len(self.proc1.state_names_dict)\n",
        "        state_names = self.proc1.state_names_dict.copy()\n",
        "        for key, val in self.proc2.state_names_dict.items():\n",
        "          # choose a unique name for merged state in case it is already occupied\n",
        "          while key in state_names:\n",
        "            key += \"_\"\n",
        "          state_names[key] = n_states\n",
        "          n_states += 1\n",
        "\n",
        "        # For a combination in which the vocabulary is disjoint, the vocab\n",
        "        # size is the sum, else the larger of the two\n",
        "        vocab_len = self.proc1.vocab_len + self.proc2.vocab_len - len(self.join_on)\n",
        "        T = np.zeros((vocab_len, n_states, n_states))\n",
        "\n",
        "        # Copying over values from Proc1\n",
        "        shape1 = self.proc1.transition_matrix.shape\n",
        "        print(shape1)\n",
        "        T[:shape1[0],:shape1[1],:shape1[2]] = self.proc1.transition_matrix\n",
        "\n",
        "        # Copying from Proc2\n",
        "        new_v = 0 # This counts the number of new vocabulary tokens\n",
        "        for v in range(self.proc2.vocab_len):\n",
        "          if v in self.join_on:\n",
        "            T[self.join_on[v],shape1[1]:, shape1[2]:] = self.proc2.transition_matrix[v,:,:]\n",
        "          else:\n",
        "            T[shape1[0]+new_v,shape1[1]:, shape1[2]:] = self.proc2.transition_matrix[v,:,:]\n",
        "            new_v += 1\n",
        "\n",
        "        print(T)\n",
        "        return T, state_names\n",
        "\n",
        "  @property\n",
        "  def steady_state_vector(self):\n",
        "      steady_state_vector = np.concatenate((self.proc1.steady_state_vector * self.weights[0], self.proc2.steady_state_vector * self.weights[1]))\n",
        "      #steady_state_vector = np.ones((self.num_states))\n",
        "\n",
        "      out = steady_state_vector / steady_state_vector.sum()\n",
        "      assert out.ndim == 1\n",
        "      assert len(out) == self.num_states\n",
        "      return out\n",
        "\n",
        "\n",
        "class BiasedCoin(Process):\n",
        "    def __init__(self, bias: float = 0.5):\n",
        "        self.name = \"bc\"\n",
        "        self.p = bias\n",
        "        super().__init__()\n",
        "\n",
        "    def _create_hmm(self):\n",
        "        T = np.zeros((2, 1, 1))\n",
        "        state_names = {\"0\": 0}\n",
        "        T[0, state_names[\"0\"], state_names[\"0\"]] = self.p\n",
        "        T[1, state_names[\"0\"], state_names[\"0\"]] = 1-self.p\n",
        "\n",
        "        return T, state_names\n"
      ],
      "metadata": {
        "id": "CIaVSyo3puiV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.visualization.graph import transition_matrix_to_graph, visualize_graph\n",
        "\n",
        "graph = transition_matrix_to_graph(transition_matrix=gp.transition_matrix,state_names=gp.state_names_dict)\n",
        "visualize_graph(graph, draw_mixed_state=True, layout=\"circular\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "jpz55-CBtYO2",
        "outputId": "f3af0be5-c4e5-4ce2-984a-168edf759059"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-766afeab2735>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mepsilon_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransition_matrix_to_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition_matrix_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_names_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvisualize_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_mixed_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"circular\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.visualization.plots import _project_to_simplex\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "proc1 = BiasedCoin(0.5)\n",
        "proc2 = BiasedCoin(0.3)\n",
        "proc3 = BiasedCoin(0.7)\n",
        "process = GluedProcess(proc3, GluedProcess(proc1, proc2, {0:0}), {0:0,1:1}, weights=(1, 2))\n",
        "mixed_state_tree = process.derive_mixed_state_presentation(depth=14)\n",
        "MSP_transition_matrix = mixed_state_tree.build_msp_transition_matrix()\n",
        "\n",
        "tree_paths, tree_beliefs = mixed_state_tree.paths_and_belief_states\n",
        "\n",
        "msp_beliefs = [tuple(round(b, 5) for b in belief) for belief in tree_beliefs]\n",
        "msp_belief_index = {b: i for i, b in enumerate(set(msp_beliefs))}\n",
        "ground_truth_simplex = _project_to_simplex(np.array(list(msp_belief_index.keys())))\n",
        "plt.figure(figsize=(4.5, 4))\n",
        "plt.scatter(ground_truth_simplex[0], ground_truth_simplex[1], c=[k for k in list(msp_belief_index.keys())], alpha=.75, s=5)\n",
        "plt.title(\"Ground Truth Simplex\")\n",
        "plt.gca().set_axis_off()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "RoJ-QZgithtp",
        "outputId": "a2cc3870-944e-423f-94bd-f69cb9fc1f3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 1, 1)\n",
            "[[[0.5 0. ]\n",
            "  [0.  0.3]]\n",
            "\n",
            " [[0.5 0. ]\n",
            "  [0.  0. ]]\n",
            "\n",
            " [[0.  0. ]\n",
            "  [0.  0.7]]]\n",
            "(2, 1, 1)\n",
            "[[[0.7 0.  0. ]\n",
            "  [0.  0.5 0. ]\n",
            "  [0.  0.  0.3]]\n",
            "\n",
            " [[0.3 0.  0. ]\n",
            "  [0.  0.5 0. ]\n",
            "  [0.  0.  0. ]]\n",
            "\n",
            " [[0.  0.  0. ]\n",
            "  [0.  0.  0. ]\n",
            "  [0.  0.  0.7]]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 450x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer training\n"
      ],
      "metadata": {
        "id": "0j8974VJ6bwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "eBoj5FRhEB4O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.persistence import S3Persister, HackyPersister\n",
        "from epsilon_transformers.training.configs.model_configs import RawModelConfig\n",
        "from epsilon_transformers.process.processes import RRXOR, Mess3\n",
        "from epsilon_transformers.analysis.activation_analysis import get_beliefs_for_transformer_inputs\n",
        "from epsilon_transformers.visualization.plots import _project_to_simplex\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "Qj86qldcENSL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transformer_data_from_process(process, n_ctx):\n",
        "    mixed_state_tree = process.derive_mixed_state_presentation(depth=n_ctx+1)\n",
        "    tree_paths, tree_beliefs = mixed_state_tree.paths_and_belief_states\n",
        "    transformer_data = [x for x in tree_paths if len(x) == n_ctx+1]\n",
        "    transformer_data = torch.tensor(transformer_data)\n",
        "    transformer_input = transformer_data[:, :-1]\n",
        "    transformer_target = transformer_data[:, 1:]\n",
        "    return transformer_input, transformer_target\n",
        "\n",
        "def get_lower_bound_for_cross_entropy(process, n_ctx):\n",
        "    mixed_state_tree = process.derive_mixed_state_presentation(depth=n_ctx+1)\n",
        "    myopic_entropy = mixed_state_tree.myopic_entropy\n",
        "    return myopic_entropy[1:]"
      ],
      "metadata": {
        "id": "z83TDfiCEVX7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = HookedTransformerConfig(\n",
        "    n_layers = 1,\n",
        "    n_heads = 3,\n",
        "    d_model = 9,\n",
        "    d_head = 3,\n",
        "    d_mlp = 9,\n",
        "    act_fn = \"relu\",\n",
        "    normalization_type=None,\n",
        "    d_vocab=3,\n",
        "    n_ctx=8,\n",
        "    init_weights=True,\n",
        "    device=device,\n",
        "    seed = 999,\n",
        ")"
      ],
      "metadata": {
        "id": "Skv_LKl8Ekw0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from typing import List, Tuple, Iterable\n",
        "\n",
        "\n",
        "class ProcessDataset(IterableDataset):\n",
        "\n",
        "    def __init__(self, process, sequence_length, num_samples, fixed=False):\n",
        "        super().__init__()\n",
        "        self.process = process\n",
        "        self.sequence_length = sequence_length\n",
        "        self.num_samples = num_samples\n",
        "        self.fixed = fixed\n",
        "        if self.fixed:\n",
        "          self.samples = list(self._get_samples())\n",
        "        else:\n",
        "          self.samples = None\n",
        "\n",
        "    def _get_samples(self):\n",
        "      return process.yield_emissions(\n",
        "            sequence_len=self.num_samples * (self.sequence_length + 1)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __iter__(self) -> Iterable[Tuple[List[int]]]:\n",
        "        samples = self._get_samples() if self.samples is None else iter(self.samples)\n",
        "        for _ in range(self.num_samples):\n",
        "            process_history = [\n",
        "                next(samples) for _ in range(self.sequence_length + 1)\n",
        "            ]\n",
        "            yield (process_history[:-1], process_history[1:])\n",
        "\n",
        "\n",
        "def process_dataset_collate_fn(batch: List[Tuple[List[int]]]):\n",
        "    data = [x[0] for x in batch]\n",
        "    labels = [x[1] for x in batch]\n",
        "    return torch.tensor(data, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "\n",
        "train_dataset = ProcessDataset(process, sequence_length=cfg.n_ctx, num_samples=10000,\n",
        "                                     fixed=False)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=100, collate_fn=process_dataset_collate_fn)\n",
        "val_dataset = ProcessDataset(process, sequence_length=cfg.n_ctx, num_samples=1000,\n",
        "                                   fixed=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=100, collate_fn=process_dataset_collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "xuMTautumzgr",
        "outputId": "b53c0854-aac5-474d-eed7-16dc8f8e387c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'n_ctx' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f99cc7f1fd94>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m                                      fixed=False)\n\u001b[1;32m     44\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_dataset_collate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m val_dataset = ProcessDataset(process, sequence_length=n_ctx, num_samples=1000,\n\u001b[0m\u001b[1;32m     46\u001b[0m                                    fixed=True)\n\u001b[1;32m     47\u001b[0m \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_dataset_collate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'n_ctx' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "proc1 = BiasedCoin(0.5)\n",
        "proc2 = BiasedCoin(0.3)\n",
        "proc3 = BiasedCoin(0.7)\n",
        "process = GluedProcess(proc3, GluedProcess(proc1, proc2, {0:0}), {0:0,1:1}, weights=(1, 2))\n",
        "transformer_inputs, transformer_targets = get_transformer_data_from_process(process, cfg.n_ctx)\n",
        "minimum_loss = np.mean(get_lower_bound_for_cross_entropy(process, cfg.n_ctx))\n",
        "print(f\"Minimum Loss: {minimum_loss}\")\n",
        "transformer_inputs = transformer_inputs.to(device)\n",
        "transformer_targets = transformer_targets.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYnAUPesEstY",
        "outputId": "ed48cd02-af65-4945-be19-baab7573594b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 1, 1)\n",
            "[[[0.5 0. ]\n",
            "  [0.  0.3]]\n",
            "\n",
            " [[0.5 0. ]\n",
            "  [0.  0. ]]\n",
            "\n",
            " [[0.  0. ]\n",
            "  [0.  0.7]]]\n",
            "(2, 1, 1)\n",
            "[[[0.7 0.  0. ]\n",
            "  [0.  0.5 0. ]\n",
            "  [0.  0.  0.3]]\n",
            "\n",
            " [[0.3 0.  0. ]\n",
            "  [0.  0.5 0. ]\n",
            "  [0.  0.  0. ]]\n",
            "\n",
            " [[0.  0.  0. ]\n",
            "  [0.  0.  0. ]\n",
            "  [0.  0.  0.7]]]\n",
            "Minimum Loss: 0.6859985357149234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = HookedTransformer(cfg)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)"
      ],
      "metadata": {
        "id": "7xKW7GVvFMaV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "for epoch in tqdm(range(10000)):\n",
        "    train_logits = model(transformer_inputs)\n",
        "    train_loss = loss_fn(train_logits.view(-1, cfg.d_vocab), transformer_targets.flatten())\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{10000}, Loss: {train_loss.item()/minimum_loss*100} percent of minimum, LR: {optimizer.param_groups[0]['lr']}\")\n",
        "        scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iylTEAD_FQvp",
        "outputId": "02eb1494-4ae2-4389-b561-12f90641085a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 10/10000 [00:00<03:41, 45.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000, Loss: 167.16372051398648 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 106/10000 [00:02<03:20, 49.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101/10000, Loss: 121.71053764922473 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 207/10000 [00:04<03:20, 48.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 201/10000, Loss: 112.03300781509935 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 306/10000 [00:06<05:01, 32.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 301/10000, Loss: 109.27813781204902 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 410/10000 [00:09<03:13, 49.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 401/10000, Loss: 108.24576752121496 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 508/10000 [00:11<03:13, 49.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 501/10000, Loss: 107.87693041166074 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 609/10000 [00:13<03:06, 50.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 601/10000, Loss: 107.72360017674191 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 710/10000 [00:15<03:04, 50.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 701/10000, Loss: 107.64555789363199 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 810/10000 [00:17<03:13, 47.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 801/10000, Loss: 107.59819555949346 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 906/10000 [00:20<04:49, 31.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 901/10000, Loss: 107.56556064351028 percent of minimum, LR: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1009/10000 [00:23<03:39, 40.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1001/10000, Loss: 107.56253696119875 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 1105/10000 [00:25<05:43, 25.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1101/10000, Loss: 107.5598608285782 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 1206/10000 [00:29<05:43, 25.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1201/10000, Loss: 107.55724551715356 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 1306/10000 [00:36<06:09, 23.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1301/10000, Loss: 107.55469971566711 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 1405/10000 [00:40<05:50, 24.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1401/10000, Loss: 107.55220604663431 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 1505/10000 [00:45<06:00, 23.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1501/10000, Loss: 107.549790576282 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 1604/10000 [00:51<05:26, 25.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1601/10000, Loss: 107.54742723838334 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 1709/10000 [00:54<02:59, 46.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1701/10000, Loss: 107.54514209916512 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 1810/10000 [00:56<02:49, 48.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1801/10000, Loss: 107.54291778114285 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 1906/10000 [00:58<02:54, 46.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1901/10000, Loss: 107.54073690683192 percent of minimum, LR: 0.010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2003/10000 [01:02<07:22, 18.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2001/10000, Loss: 107.54050231079052 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 2110/10000 [01:05<02:45, 47.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2101/10000, Loss: 107.54028509223366 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 2209/10000 [01:07<02:39, 48.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2201/10000, Loss: 107.54007656241906 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 2307/10000 [01:09<02:35, 49.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2301/10000, Loss: 107.53986803260447 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 2406/10000 [01:11<02:30, 50.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2401/10000, Loss: 107.53964212530533 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 2511/10000 [01:13<02:28, 50.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2501/10000, Loss: 107.53943359549073 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 2604/10000 [01:16<04:14, 29.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2601/10000, Loss: 107.53922506567616 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 2708/10000 [01:18<02:28, 49.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2701/10000, Loss: 107.53901653586158 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 2810/10000 [01:21<02:31, 47.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2801/10000, Loss: 107.53879062856244 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 2907/10000 [01:23<02:27, 47.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2901/10000, Loss: 107.53858209874785 percent of minimum, LR: 0.0010000000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3009/10000 [01:25<02:20, 49.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3001/10000, Loss: 107.53858209874785 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 3103/10000 [01:26<02:17, 50.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3101/10000, Loss: 107.53853865503646 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 3210/10000 [01:30<02:47, 40.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3201/10000, Loss: 107.5385299662942 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 3306/10000 [01:32<02:18, 48.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3301/10000, Loss: 107.53851258880964 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 3407/10000 [01:34<02:20, 46.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3401/10000, Loss: 107.53847783384055 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 3509/10000 [01:36<02:18, 46.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3501/10000, Loss: 107.53846914509828 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 3607/10000 [01:38<02:10, 48.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3601/10000, Loss: 107.53845176761372 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 3704/10000 [01:40<03:09, 33.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3701/10000, Loss: 107.5384257013869 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 3808/10000 [01:44<02:11, 47.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3801/10000, Loss: 107.53840832390236 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 3910/10000 [01:46<02:06, 48.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3901/10000, Loss: 107.53837356893325 percent of minimum, LR: 0.00010000000000000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4009/10000 [01:48<02:01, 49.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4001/10000, Loss: 107.53838225767554 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 4107/10000 [01:50<02:02, 48.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4101/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 4209/10000 [01:52<01:55, 50.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4201/10000, Loss: 107.53838225767554 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 4305/10000 [01:55<03:02, 31.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4301/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 4407/10000 [01:58<02:16, 41.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4401/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 4505/10000 [02:01<03:06, 29.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4501/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 4605/10000 [02:05<02:58, 30.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4601/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 4706/10000 [02:09<03:07, 28.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4701/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 4808/10000 [02:11<01:41, 50.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4801/10000, Loss: 107.53838225767554 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 4907/10000 [02:13<01:46, 47.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4901/10000, Loss: 107.53839094641779 percent of minimum, LR: 1.0000000000000004e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5008/10000 [02:15<01:43, 48.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5001/10000, Loss: 107.53839094641779 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 5107/10000 [02:17<01:40, 48.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5101/10000, Loss: 107.53839094641779 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 5206/10000 [02:19<01:40, 47.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5201/10000, Loss: 107.53839094641779 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 5306/10000 [02:23<02:36, 30.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5301/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 5411/10000 [02:25<01:35, 48.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5401/10000, Loss: 107.53838225767554 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 5507/10000 [02:27<01:31, 48.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5501/10000, Loss: 107.53839094641779 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 5607/10000 [02:29<01:27, 50.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5601/10000, Loss: 107.53838225767554 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 5706/10000 [02:31<01:33, 45.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5701/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 5803/10000 [02:33<01:37, 43.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5801/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 5907/10000 [02:36<01:45, 38.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5901/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000004e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6006/10000 [02:38<01:23, 48.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6001/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 6110/10000 [02:40<01:19, 48.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6101/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 6206/10000 [02:42<01:15, 50.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6201/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 6307/10000 [02:44<01:17, 47.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6301/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 6407/10000 [02:46<01:45, 34.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6401/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 6507/10000 [02:50<01:17, 44.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6501/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 6609/10000 [02:52<01:11, 47.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6601/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 6707/10000 [02:54<01:07, 48.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6701/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 6808/10000 [02:56<01:06, 47.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6801/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 6907/10000 [02:58<01:02, 49.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6901/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7007/10000 [03:01<01:36, 31.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7001/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 7110/10000 [03:04<00:57, 50.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7101/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 7206/10000 [03:05<00:55, 50.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7201/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 7308/10000 [03:07<00:53, 50.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7301/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 7409/10000 [03:10<00:49, 51.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7401/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 7509/10000 [03:12<00:52, 47.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7501/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 7603/10000 [03:16<02:30, 15.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7601/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 7706/10000 [03:20<01:15, 30.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7701/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 7808/10000 [03:22<00:44, 49.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7801/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 7909/10000 [03:24<00:43, 48.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7901/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8006/10000 [03:27<01:03, 31.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8001/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 8109/10000 [03:31<00:42, 44.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8101/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 8206/10000 [03:35<01:03, 28.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8201/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 8305/10000 [03:38<01:00, 28.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8301/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 8404/10000 [03:44<01:02, 25.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8401/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 8504/10000 [03:47<00:50, 29.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8501/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 8605/10000 [03:51<00:46, 29.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8601/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 8704/10000 [03:54<00:38, 33.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8701/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 8806/10000 [03:57<00:25, 47.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8801/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 8906/10000 [03:59<00:22, 48.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8901/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000005e-09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9010/10000 [04:01<00:20, 49.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9001/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 9110/10000 [04:03<00:17, 49.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9101/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 9211/10000 [04:05<00:15, 50.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9201/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 9304/10000 [04:08<00:21, 31.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9301/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 9410/10000 [04:10<00:12, 47.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9401/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 9510/10000 [04:13<00:10, 47.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9501/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 9607/10000 [04:15<00:08, 47.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9601/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 9709/10000 [04:17<00:05, 50.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9701/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 9806/10000 [04:19<00:04, 48.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9801/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 9904/10000 [04:21<00:03, 31.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9901/10000, Loss: 107.53837356893325 percent of minimum, LR: 1.0000000000000006e-10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [04:24<00:00, 37.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "# 保存整个模型到当前工作目录\n",
        "torch.save(model, 'my_model.pth')\n",
        "\n"
      ],
      "metadata": {
        "id": "1TrDvgmKCXq4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr2SMe39Uo4D",
        "outputId": "15360f8d-22e0-4bb5-a78c-7818c897ccd4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 52\n",
            "drwxr-xr-x 8 root root  4096 Jun  2 19:51 epsilon-transformers\n",
            "drwxr-xr-x 8 root root  4096 Jun  2 17:28 epsilon_transformers\n",
            "drwxr-xr-x 2 root root  4096 Jun  2 19:55 epsilon_transformers.egg-info\n",
            "drwxr-xr-x 2 root root  4096 Jun  2 17:26 examples\n",
            "-rw-r--r-- 1 root root 19574 Jun  2 20:01 my_model.pth\n",
            "-rw-r--r-- 1 root root   584 Jun  2 17:26 pyproject.toml\n",
            "-rw-r--r-- 1 root root  2686 Jun  2 17:26 README.md\n",
            "drwxr-xr-x 2 root root  4096 Jun  2 17:26 scripts\n",
            "drwxr-xr-x 2 root root  4096 Jun  2 17:26 tests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载模型\n",
        "loaded_model = torch.load('my_model.pth')\n",
        "\n",
        "# 检查模型是否相同\n",
        "# 这可以通过比较某些输出或模型参数来进行\n",
        "input_example = torch.randint(low=0, high=proc1.vocab_len, size=(1, 8))  # 假设词汇表大小为vocab_size\n",
        "input_example = input_example.long()  # 转换输入数据类型\n",
        "original_output = model(input_example)\n",
        "loaded_output = loaded_model(input_example)\n",
        "print(torch.equal(original_output, loaded_output))  # 输出应该是 True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQYwhbJDVBbB",
        "outputId": "70d1cca0-4a7b-43fb-a760-b43957954006"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "transformer_inputs = [x for x in tree_paths if len(x) == cfg.n_ctx]\n",
        "transformer_inputs = torch.tensor(transformer_inputs, dtype=torch.int).to(device)\n",
        "\n",
        "# print first few batches\n",
        "print(transformer_inputs[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufjqUp0sWKNk",
        "outputId": "a4593e3e-bbe2-45e1-af48-0fd0114857de"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 2, 2, 0, 0, 0, 0],\n",
            "        [0, 0, 2, 2, 0, 0, 0, 2],\n",
            "        [0, 2, 2, 0, 0, 2, 0, 0],\n",
            "        [0, 2, 2, 0, 0, 2, 0, 2],\n",
            "        [0, 1, 0, 1, 1, 1, 1, 0]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_input_beliefs, transformer_input_belief_indices = get_beliefs_for_transformer_inputs(transformer_inputs, msp_belief_index, tree_paths, tree_beliefs)\n",
        "print(f\"Transformer Input Beliefs: {transformer_input_beliefs.shape}, Transformer Input Belief Indices: {transformer_input_belief_indices.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgVaarV5W5jV",
        "outputId": "f86eb4f3-5289-47d7-87a6-8a18f4d35ae9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer Input Beliefs: torch.Size([511, 8, 3]), Transformer Input Belief Indices: torch.Size([511, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = torch.load('my_model.pth')\n",
        "_, activations = model.run_with_cache(transformer_inputs, names_filter=lambda x: 'resid_post' in x)\n",
        "print(activations.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW9WHw3CY2Wl",
        "outputId": "bbe86027-d1ea-4758-e9d3-9b8e3f66dbca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['blocks.0.hook_resid_post'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we now have activations [batch, n_ctx, d_model]\n",
        "# and we have transformer_input_beliefs [batch, n_ctx, belief_dim]\n",
        "# and we have transformer_input_belief_indices [batch, n_ctx]\n",
        "\n",
        "# in the end we want to do linear regression between the activations and the transformer_input_beliefs\n",
        "def run_activation_to_beliefs_regression(activations, ground_truth_beliefs):\n",
        "\n",
        "    # make sure the first two dimensions are the same\n",
        "    assert activations.shape[0] == ground_truth_beliefs.shape[0]\n",
        "    assert activations.shape[1] == ground_truth_beliefs.shape[1]\n",
        "\n",
        "    # flatten the activations\n",
        "    batch_size, n_ctx, d_model = activations.shape\n",
        "    belief_dim = ground_truth_beliefs.shape[-1]\n",
        "    activations_flattened = activations.view(-1, d_model) # [batch * n_ctx, d_model]\n",
        "    ground_truth_beliefs_flattened = ground_truth_beliefs.view(-1, belief_dim) # [batch * n_ctx, belief_dim]\n",
        "\n",
        "    # run the regression\n",
        "    regression = LinearRegression()\n",
        "    regression.fit(activations_flattened, ground_truth_beliefs_flattened)\n",
        "\n",
        "    # get the belief predictions\n",
        "    belief_predictions = regression.predict(activations_flattened) # [batch * n_ctx, belief_dim]\n",
        "    belief_predictions = belief_predictions.reshape(batch_size, n_ctx, belief_dim)\n",
        "\n",
        "    return regression, belief_predictions\n"
      ],
      "metadata": {
        "id": "-dZE9wz0bPL2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acts = torch.cat([v for k, v in activations.items()], dim=-1)\n",
        "regression, belief_predictions = run_activation_to_beliefs_regression(acts, transformer_input_beliefs)\n",
        "print(f\"Shape of belief_predictions: {belief_predictions.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6Hj5Rc_bSbg",
        "outputId": "42aa35d4-c473-4344-9ecd-35473a8d0974"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of belief_predictions: (511, 8, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.visualization import plots\n",
        "print(dir(plots))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcIPPJhvjVIK",
        "outputId": "73df2f25-fff2-43a6-84fe-7c87d39c2f28"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Figure', 'Float', 'Image', 'Literal', 'RawModelConfig', 'ZeroOneR', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_project_to_simplex', 'find_msp_subspace_in_residual_stream', 'fire', 'np', 'pd', 'plt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from epsilon_transformers.analysis.activation_analysis import find_msp_subspace_in_residual_stream\n",
        "from epsilon_transformers.process.processes import Mess3\n",
        "\n",
        "\n",
        "belief_predictions_flattened = belief_predictions.reshape(-1, 3)\n",
        "transformer_input_belief_flattened = transformer_input_beliefs.reshape(-1, 3)\n",
        "\n",
        "# project to simplex\n",
        "belief_true_projected = _project_to_simplex(transformer_input_belief_flattened)\n",
        "belief_pred_projected = _project_to_simplex(belief_predictions_flattened)\n",
        "\n",
        "rgb_colors =  transformer_input_belief_flattened.cpu().numpy()\n",
        "#rgb_colors = rgb_colors.astype(int)\n",
        "\n",
        "sns.set_context(\"paper\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
        "\n",
        "# Plotting the true beliefs projected onto the simplex\n",
        "axes[0].scatter(belief_true_projected[0], belief_true_projected[1], marker='.', c=rgb_colors, alpha=0.2, s=0.5)\n",
        "axes[0].axis('off')\n",
        "axes[0].set_title(\"Ground Truth Simplex\")\n",
        "\n",
        "# Plotting the predicted beliefs projected onto the simplex\n",
        "axes[1].scatter(belief_pred_projected[0], belief_pred_projected[1], marker='.', c=rgb_colors, alpha=0.3, s=0.01)\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title(\"Residual Stream Simplex\")\n",
        "\n",
        "# Adjust layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "QsNXkP8XdLs7",
        "outputId": "918c6023-3a7a-4534-97f5-5bf0053cbe4a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}